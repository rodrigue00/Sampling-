import pandas as pd
import json
import pickle
import optuna
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 1. Charger la configuration depuis le fichier config.json
with open("config.json", "r") as config_file:
    config = json.load(config_file)

file_path = config["file_path"]
file_type = config["file_type"].lower()

# 2. Charger les donn√©es en fonction du type de fichier
try:
    if file_type == "csv":
        df = pd.read_csv(file_path)  # Charger un fichier CSV
    elif file_type == "json":
        df = pd.read_json(file_path)  # Charger un fichier JSON
    elif file_type == "excel":
        df = pd.read_excel(file_path)  # Charger un fichier Excel
    else:
        raise ValueError("Format de fichier non pris en charge : choisissez 'csv', 'json' ou 'excel'.")
    
    # Afficher les premi√®res lignes des donn√©es charg√©es
    print("Donn√©es charg√©es avec succ√®s :")
    
     # 3. Comprendre les donn√©es
     
     # Afficher les premi√®res lignes
    print("\nüîç Aper√ßu des donn√©es :")
    print(df.head())
    
    # Informations g√©n√©rales sur les donn√©es
    df.info()

    # V√©rifier la taille du dataset
    print("\n Dimensions du dataset (lignes, colonnes) :", df.shape)

    # V√©rifier les types de donn√©es
    print("\n Types de donn√©es par colonne :")
    print(df.dtypes)

    # V√©rifier les valeurs manquantes
    print("\n Valeurs manquantes par colonne :")
    print(df.isnull().sum())
    
    # V√©rifier le nombre de valeurs uniques par colonne
    print("\n Nombre de valeurs uniques par colonne :")
    print(df.nunique())
    
    # D√©tecter les doublons
    print("\n Nombre de lignes dupliqu√©es :", df.duplicated().sum())

    # Statistiques descriptives
    print("\n Statistiques descriptives :")
    print(df.describe())
    
    # V√©rifier l‚Äô√©quilibre des classes (si une colonne 'target' existe)
    target_column = "target"  # Modifier si besoin
    if target_column in df.columns:
        print(f"\n Distribution des classes dans '{target_column}' :")
        print(df[target_column].value_counts())
    
    # 4. S√©paration des donn√©es en entra√Ænement et test
    if config.get("train_test_split", False):
        test_size = config.get("test_size", 0.2)
        random_state = config.get("random_state", 42)

        # V√©rifier si la colonne 'target' existe pour la s√©paration
        if target_column in df.columns:
            X = df.drop(columns=[target_column])
            y = df[target_column]

            # S√©parer les donn√©es
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

            print(f"\n  Donn√©es s√©par√©es : {100 * (1 - test_size)}% pour l'entra√Ænement, {100 * test_size}% pour le test")
            print(f"   - X_train : {X_train.shape}, X_test : {X_test.shape}")
            print(f"   - y_train : {y_train.shape}, y_test : {y_test.shape}")
        else:
            print("\n  Aucune colonne 'target' trouv√©e. La s√©paration train-test n'a pas √©t√© effectu√©e.")
    
    # 5. S√©lection et entra√Ænement des mod√®les
    models = {
        "Decision Tree": DecisionTreeClassifier(random_state=random_state),
        "Random Forest": RandomForestClassifier(random_state=random_state),
        "SVM": SVC(random_state=random_state),
        "Neural Network": MLPClassifier(random_state=random_state, max_iter=500)
    }

    results = {}

    for model_name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # √âvaluation
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

        # Validation crois√©e
        cross_val = cross_val_score(model, X_train, y_train, cv=5).mean()

        results[model_name] = {
            "Accuracy": accuracy,
            "Precision": precision,
            "Recall": recall,
            "F1-score": f1,
            "Cross-validation score": cross_val
        }

    print("\n R√©sultats des mod√®les avant optimisation :")
    for model, metrics in results.items():
        print(f"\n {model}:")
        for metric, value in metrics.items():
            print(f"   - {metric}: {value:.4f}")

    # 6. Optimisation des hyperparam√®tres avec Optuna
    best_params = {}

    if config["use_optuna"]:
        def objective(trial):
            model_name = trial.suggest_categorical("model", list(models.keys()))

            if model_name == "Decision Tree":
                max_depth = trial.suggest_int("max_depth", 2, 20)
                model = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)

            elif model_name == "Random Forest":
                n_estimators = trial.suggest_int("n_estimators", 10, 200)
                max_depth = trial.suggest_int("max_depth", 2, 20)
                model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)

            elif model_name == "SVM":
                C = trial.suggest_loguniform("C", 0.1, 10)
                kernel = trial.suggest_categorical("kernel", ["linear", "rbf", "poly"])
                model = SVC(C=C, kernel=kernel, random_state=random_state)

            elif model_name == "Neural Network":
                hidden_layer_sizes = trial.suggest_categorical("hidden_layer_sizes", [(50,), (100,), (50, 50)])
                learning_rate_init = trial.suggest_loguniform("learning_rate_init", 0.0001, 0.1)
                model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, learning_rate_init=learning_rate_init, max_iter=500, random_state=random_state)

            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            return accuracy_score(y_test, y_pred)

        study = optuna.create_study(direction="maximize")
        study.optimize(objective, n_trials=config["n_trials"])

        print("\nMeilleur mod√®le optimis√© avec Optuna :")
        print(study.best_trial)

        best_params = study.best_trial.params

    # 7. R√©entra√Æner les mod√®les avec les meilleurs hyperparam√®tres
    if config["retrain_with_best_params"]:
        for model_name in models.keys():
            if model_name in best_params:
                if model_name == "Decision Tree":
                    model = DecisionTreeClassifier(max_depth=best_params["max_depth"], random_state=random_state)

                elif model_name == "Random Forest":
                    model = RandomForestClassifier(n_estimators=best_params["n_estimators"], max_depth=best_params["max_depth"], random_state=random_state)

                elif model_name == "SVM":
                    model = SVC(C=best_params["C"], kernel=best_params["kernel"], random_state=random_state)

                elif model_name == "Neural Network":
                    model = MLPClassifier(hidden_layer_sizes=best_params["hidden_layer_sizes"], learning_rate_init=best_params["learning_rate_init"], max_iter=500, random_state=random_state)

                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)

                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, average="weighted", zero_division=0)
                recall = recall_score(y_test, y_pred, average="weighted", zero_division=0)
                f1 = f1_score(y_test, y_pred, average="weighted", zero_division=0)

                print(f"\n{model_name} - Apr√®s optimisation")
                print(f"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}")

    # 8. Sauvegarde du meilleur mod√®le
    if config["save_best_model"]:
        best_model_name = max(results, key=lambda k: results[k]["Accuracy"])
        best_model = models[best_model_name]

        with open(config["best_model_path"], "wb") as model_file:
            pickle.dump(best_model, model_file)

        print(f"\n Meilleur mod√®le '{best_model_name}' sauvegard√© sous '{config['best_model_path']}'")

   

except FileNotFoundError:
    print(f"Erreur : Le fichier '{file_path}' n'existe pas. V√©rifiez le chemin.")
except Exception as e:
    print(f"Erreur lors de l'analyse des donn√©es : {e}")
    
