# üîπ G√©rer les valeurs manquantes
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Chargement du DataFrame (Remplacez ceci par votre propre m√©thode de chargement)
# df = pd.read_csv("data/raw_data.csv")

# V√©rifier les valeurs manquantes
print("\nValeurs manquantes avant traitement :")
print(df.isnull().sum())

# Remplir les valeurs manquantes pour les variables num√©riques avec la m√©diane
if not df.empty:
    df.fillna(df.median(numeric_only=True), inplace=True)

# Remplir les valeurs manquantes pour les variables cat√©goriques avec le mode
for col in df.select_dtypes(include=['object']).columns:
    if df[col].isnull().sum() > 0:  # V√©rifier s'il y a des valeurs manquantes
        df[col].fillna(df[col].mode()[0], inplace=True)

print("\nValeurs manquantes trait√©es.")

# Gestion des doublons
nb_duplicated = df.duplicated().sum()
if nb_duplicated > 0:
    df.drop_duplicates(inplace=True)
    print(f"\n{nb_duplicated} doublon(s) supprim√©(s).")
else:
    print("\nAucun doublon d√©tect√©.")

# Encodage des variables cat√©goriques
categorical_cols = df.select_dtypes(include=['object']).columns

if len(categorical_cols) > 0:
    encoder = LabelEncoder()
    for col in categorical_cols:
        df[col] = encoder.fit_transform(df[col].astype(str))  # Conversion en string pour √©viter les erreurs
    print("\nEncodage des variables cat√©goriques effectu√©.")

# Normalisation des variables num√©riques
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns

if len(numerical_cols) > 0:
    scaler = StandardScaler()
    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
    print("\nNormalisation des donn√©es termin√©e.")

# Affichage des donn√©es apr√®s pr√©traitement
print("\nAper√ßu des donn√©es apr√®s pr√©traitement :")
print(df.head())

# Sauvegarde des donn√©es pr√©trait√©es
output_path = "data/cleaned_data.csv"
df.to_csv(output_path, index=False)
print(f"\nDonn√©es pr√©trait√©es enregistr√©es sous '{output_path}'.")











 #  Gestion du d√©s√©quilibre des classes
    X = df.drop(columns=[target_col])
    y = df[target_col]

    print("\n Distribution des classes avant √©quilibrage :", Counter(y))

    # Choisir entre sur-√©chantillonnage ou sous-√©chantillonnage
    strategy = "smote"  # Options : "smote", "undersampling", "none"

    if strategy == "smote":
        smote = SMOTE(sampling_strategy='auto', random_state=42)
        X_resampled, y_resampled = smote.fit_resample(X, y)
        print("\n Sur-√©chantillonnage avec SMOTE effectu√©.")
    elif strategy == "undersampling":
        undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)
        X_resampled, y_resampled = undersampler.fit_resample(X, y)
        print("\n Sous-√©chantillonnage effectu√©.")
    else:
        X_resampled, y_resampled = X, y

    print("\n R√©partition des classes apr√®s √©quilibrage :", Counter(y_resampled))

    #  Sauvegarde des donn√©es pr√©trait√©es
    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)
    df_resampled[target_col] = y_resampled
    output_path = "data/cleaned_balanced_data.csv"
    df_resampled.to_csv(output_path, index=False)

    print(f"\n Donn√©es √©quilibr√©es enregistr√©es sous '{output_path}'.")